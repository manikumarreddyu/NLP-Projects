{"searchParameters": {"q": "What is Direct Preference Optimization?", "type": "search", "engine": "google"}, "answerBox": {"snippet": "With direct preference optimization (DPO), a language model can be aligned with human preferences without using reinforcement learning, thereby significantly simplifying the training process.", "snippetHighlighted": ["a language model can be aligned with human preferences without using reinforcement learning"], "title": "Direct Preference Optimization | appliedAI Institute \u2014 TransferLab", "link": "https://transferlab.appliedai.de/pills/2023/direct-preference-optmization/", "date": "Jul 6, 2023"}, "organic": [{"title": "[2305.18290] Direct Preference Optimization: Your Language Model is Secretly a Reward Model - arXiv", "link": "https://arxiv.org/abs/2305.18290", "snippet": "The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant and computationally lightweight, eliminating ...", "date": "May 29, 2023", "position": 1}, {"title": "Direct Preference Optimization in One Minute - LessWrong", "link": "https://www.lesswrong.com/posts/7ruzY5LvBqFBWzyMo/direct-preference-optimization-in-one-minute", "snippet": "In essence, DPO computes the log probabilities of preferred and dispreferred completions under the current model and optimizes parameters to ...", "date": "Jun 26, 2023", "position": 2}, {"title": "eric-mitchell/direct-preference-optimization - DPO - GitHub", "link": "https://github.com/eric-mitchell/direct-preference-optimization", "snippet": "This repo includes a reference implementation of the DPO algorithm for training language models from preference data, as described in the paper Direct ...", "position": 3}, {"title": "Direct Preference Optimization: Forget RLHF (PPO) - YouTube", "link": "https://youtube.com/watch?v=pzh2oc6shic", "snippet": "DPO replaces RLHF: In this technical and informative video ...", "date": "Jun 6, 2023", "attributes": {"Duration": "9:10", "Posted": "Jun 6, 2023"}, "imageUrl": "https://i.ytimg.com/vi/pzh2oc6shic/default.jpg?sqp=-oaymwEECHgQQw&rs=AMzJL3kYGJ3Wlufhz_43h0SBAVLmu1u17A", "position": 4}, {"title": "Direct Preference Optimization (DPO): Your Language Model is Secretly a Reward Model Explained - YouTube", "link": "https://youtube.com/watch?v=HCFTXTn1PHA", "snippet": "Direct Preference Optimization (DPO): Your Language ...", "date": "Aug 9, 2023", "attributes": {"Duration": "36:25", "Posted": "Aug 9, 2023"}, "imageUrl": "https://i.ytimg.com/vi/HCFTXTn1PHA/default.jpg?sqp=-oaymwEECHgQQw&rs=AMzJL3kfmHjiHp16B-OobA8f-oSY8ZNVTg", "position": 5}, {"title": "Direct Preference Optimization (DPO): A Simplified Approach to Fine-tuning Large Language Models | by Ben Burtenshaw | Sep, 2023 | Medium", "link": "https://medium.com/@ben.burtenshaw/direct-preference-optimization-dpo-a-simplified-approach-to-fine-tuning-large-language-models-bae1c6d7ec29", "snippet": "Supervised fine-tuning (SFT) is the first step of DPO. SFT is a specialized method where an LLM is further trained on a labelled dataset. This ...", "date": "5 days ago", "position": 6}, {"title": "Revolutionizing Language Models: Direct Preference Optimization Aligns With Human Tastes | CJ&CO", "link": "https://www.cjco.com.au/article/news/revolutionizing-language-models-direct-preference-optimization-aligns-with-human-tastes/", "snippet": "Direct Preference Optimization (DPO) offers a promising alternative to conventional preference learning methods. The DPO algorithm is designed to overcome these ...", "position": 7}, {"title": "Paper Summary: Direct Preference Optimization: Your Language Model is Secretly a Reward Model - queirozf.com", "link": "https://queirozf.com/entries/paper-summary-direct-preference-optimization-your-language-model-is-secretly-a-reward-model", "snippet": "An approach to align pre-trained LMs to human preferences without using Reinforcement Learning (RL). WHY. Because RL-based instruction-tuning ...", "date": "Aug 2, 2023", "position": 8}, {"title": "Improving Control of Language Models with Direct Preference Optimization - Emergent Mind", "link": "https://www.emergentmind.com/posts/2305-18290-direct-preference-optimization-your", "snippet": "Summary: Researchers propose a method called Direct Preference Optimization (DPO) to improve control over large-scale unsupervised language models.", "position": 9}], "relatedSearches": [{"query": "What is direct preference optimization python"}, {"query": "What is direct preference optimization pdf"}, {"query": "What is direct preference optimization in machine learning"}, {"query": "What is direct preference optimization example"}, {"query": "Direct preference Optimization explained"}, {"query": "Direct preference optimization github"}]}